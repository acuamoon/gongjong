const video = document.getElementById("video");
const MODEL_URL = "https://acuamoon.github.io/gongjong/face_models/";

Promise.all([
  faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
  faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
  faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),
  faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),
  faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL),
]).then(webCam);


function webCam() {
  navigator.mediaDevices
    .getUserMedia({
      video: true,
      audio: false,
    })
    .then((stream) => {
      video.srcObject = stream;
    })
    .catch((error) => {
      console.log(error);
    });
}

video.addEventListener("play", () => {
  const canvas = document.getElementById('canvas');
  const displaySize = { width: video.videoWidth, height: video.videoHeight };
  canvas.width = displaySize.width;
  canvas.height = displaySize.height;
  
  faceapi.matchDimensions(canvas, displaySize);

  setInterval(async () => {
    const detections = await faceapi
      .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
      .withFaceLandmarks()
      .withFaceExpressions()
      .withAgeAndGender();
    canvas.getContext("2d").clearRect(0, 0, canvas.width, canvas.height);

    const resizedDetections = faceapi.resizeResults(detections, displaySize);

    faceapi.draw.drawDetections(canvas, resizedDetections);
    faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);

    resizedDetections.forEach((detection) => {
      const { age, gender, expressions, detection: { box } } = detection;
      
      // ê°ì • ìƒíƒœë¥¼ í•œê¸€ë¡œ ë³€í™˜
      const emotions = Object.entries(expressions)
        .sort((a, b) => b[1] - a[1])
        .map(([emotion, score]) => {
          switch (emotion) {
            case 'neutral': return 'ğŸ˜';
            case 'happy': return 'ğŸ˜Š';
            case 'sad': return 'ğŸ˜¢';
            case 'angry': return 'ğŸ˜ ';
            case 'fearful': return 'ğŸ˜¨';
            case 'disgusted': return 'ğŸ¤¢';
            case 'surprised': return 'ğŸ˜®';
            default: return '';
          }
        });

      const emotionText = emotions[0]; // ê°€ì¥ ë†’ì€ ê°ì • ìƒíƒœ

      const drawBox = new faceapi.draw.DrawBox(box, {
        label: `${Math.round(age)}ì„¸ ${gender === 'male' ? 'ë‚¨ì ' : 'ì—¬ì '} ${emotionText}`,
      });
      drawBox.draw(canvas);
    });

    console.log(detections);
  }, 100);
});
